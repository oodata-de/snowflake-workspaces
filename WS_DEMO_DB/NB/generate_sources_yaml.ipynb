{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "id": "aefbaf50-4766-45e9-9ff9-1d1dd1ca8e8f",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark import Session\nimport yaml\n\n# session = Session.builder.config(\"connection_name\", \"myconnection\").create()\n# root = Root(session)\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "543543eb-2f95-4b74-a436-55f68405a470",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "def generate_sources_yml(session: session, database_name: str, schema_name: str, output_file: str = 'sources.yml'):\n    \"\"\"\n    Generates a dbt sources.yml file from Snowflake Information Schema.\n\n    Args:\n        session: Snowpark session connected to Snowflake.\n        database_name: Name of the Snowflake database to query.\n        schema_name: Name of the Snowflake schema to query.\n        output_file: Path to the output YAML file (default: 'sources.yml').\n    \"\"\"\n    # Query INFORMATION_SCHEMA.TABLES for tables and views in the specified database and schema\n    tables_query = f\"\"\"\n    SELECT TABLE_NAME, TABLE_TYPE\n    FROM {database_name}.INFORMATION_SCHEMA.TABLES\n    WHERE TABLE_SCHEMA = '{schema_name}'\n    AND TABLE_TYPE IN ('BASE TABLE', 'VIEW')  -- Include tables and views\n    ORDER BY TABLE_NAME\n    \"\"\"\n    tables_df = session.sql(tables_query).collect()\n    \n    if not tables_df:\n        print(f\"No tables or views found in {database_name}.{schema_name}\")\n        return\n    \n    # Build the sources.yml structure\n    sources_yml = {\n        'version': 2,\n        \n        'sources': [\n            {\n                'name': f\"{(schema_name.split('_')[-1]).lower()}\",  # Source name (e.g., mydb_myschema)\n                'database': database_name.lower(),\n                'schema': schema_name.lower(),\n                'tables': []\n            }\n        ]\n    }\n    \n    source = sources_yml['sources'][0]\n\n    for table_row in tables_df:\n        table_name = table_row['TABLE_NAME']\n        table_entry = {\n            'name': table_name.lower(),\n        }\n        source['tables'].append(table_entry)\n    \n    # Write to YAML file\n    with open(output_file, 'w') as f:\n        yaml.dump(sources_yml, f, default_flow_style=False, sort_keys=False)\n    \n    print(f\"sources.yml generated successfully at {output_file}\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "562d203c-0e89-4f0a-9021-1d00ee523f59",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "database_name = \"dbt_dev\"  # Replace with actual database name\n# schema_name = \"SCH_BRONZE_INVENTORY\"      # Replace with actual schema name\nschema_df = session.table('DBT_DEV.INFORMATION_SCHEMA.SCHEMATA')\nfor schema in schema_df.collect():\n    # print(schema)\n    schema_nm = schema['SCHEMA_NAME']\n    if schema_nm.startswith('SCH_BRONZE'):\n        generate_sources_yml(session, database_name, schema_nm, f\"_{(schema_nm.split('_')[-1]).lower()}__sources.yml\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a913c7f6-97bd-4a80-9ade-7243e96655a7",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Files created in code or from the terminal exist only for the duration of the current notebook service session. \n# When the notebook service is suspended, these files are removed. \n# Only files that are uploaded or created in Snowsight persist across sessions.\n# Files created from code or the terminal do not appear in the left-hand pane. This is a temporary limitation\n# files under /workspace/<hash> created by code/terminal are typically session-scoped and can disappear when the notebook service suspends. To keep them, you should persist them to a stage or push them to Git\n\nimport os\nprint(f\"Current working directory: {os.getcwd()}\")\n\nprint(f\"Files in directory: {os.listdir()}\")\nfile_path = '_sales__sources.yml'\nprint(f\"File created at: {file_path}, size: {os.path.getsize(file_path)} bytes\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a51f0264-11b2-43ba-bcf4-cdd66b229a5f",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import shutil\n\nshutil.copy('_inventory__sources.yml', 'files')\npath_dir = '/workspace/598b666a38c489a929528c4046f9fde004c1dce47da2d799e3c9cfbd6ad96424/WS_DEMO_DB/NB/files'\nprint(f\"Files in CWD directory: {os.listdir()}\")\n\nprint(f\"Files in files directory: {os.listdir(path_dir)}\")\n",
      "outputs": [],
      "execution_count": null
    }
  ]
}